<!DOCTYPE html>
<html lang="zxx">

<head>
    <meta charset="UTF-8">
    <meta name="description" content="Conference">
    <meta name="keywords" content="Manup, unica, creative, html">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Program | BootCamp - XAI Edition</title>

    <link rel="icon" type="image/png" href="img/favicon.png"/>

    <!-- Google Font -->
    <link href="https://fonts.googleapis.com/css?family=Work+Sans:400,500,600,700,800,900&display=swap"
        rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Poppins:400,500,600,700&display=swap" rel="stylesheet">


    <!-- Css Styles -->
    <link rel="stylesheet" href="css/bootstrap.min.css" type="text/css">
    <link rel="stylesheet" href="css/font-awesome.min.css" type="text/css">
    <link rel="stylesheet" href="css/elegant-icons.css" type="text/css">
    <link rel="stylesheet" href="css/owl.carousel.min.css" type="text/css">
    <link rel="stylesheet" href="css/magnific-popup.css" type="text/css">
    <link rel="stylesheet" href="css/slicknav.min.css" type="text/css">
    <link rel="stylesheet" href="css/style.css" type="text/css">
</head>

<body>
    <!-- Page Preloder -->
    <div id="preloder">
        <div class="loader"></div>
    </div>

    <!-- Header Section Begin -->
    <header class="header-section">
        <div class="container">
            <div class="logo">
                <a href="https://rbcdsai.iitm.ac.in/">
                    <img src="img/logo_main.png" height=50 alt="">
                </a>
            </div>
            <div class="nav-menu">
                <nav class="mainmenu mobile-menu">
                    <ul>
                        <li><a href="./index.html">Home</a></li>
                        <!--<li><a href="./Application.html">Application</a></li>-->
                        <li class="active"><a href="./program.html">Program</a></li>
                            <!-- <ul class="dropdown">
                                <li><a href="#">Keynote Speakers</a></li>
                                <li><a href="#">Invited Talks</a></li>
                                <li><a href="#">Accepted Posters</a></li>
                            </ul> -->
                        </li>
                        <li><a href="./speaker.html">Speakers</a></li>
                        <li><a href="organizers.html">Organizers</a></li>
                    </ul>
                </nav>
            </div>
            <div id="mobile-menu-wrap"></div>
        </div>
    </header>
    <!-- Header End -->

    <!-- Program Hero Section Begin -->
    <!-- <section class="blog-hero-section set-bg" data-setbg="img/pricing-bg.jpg">
        <div class="container">
            <div class="row">
                <div class="col-lg-12">
                    <div class="bh-text">
                        <h2>Program Schedule</h2>
                    </div>
                </div>
            </div>
        </div>
    </section> -->
    <!-- Program Hero Section End -->

    <!-- Breadcrumb Section Begin -->
    <section class="breadcrumb-section">
        <div class="container">
            <div class="row">
                <div class="col-lg-12">
                    <div class="breadcrumb-text">
                        <h2>Program Schedule</h2>
                        <div class="bt-option">
                            <a href="./index.html">Home</a>
                            <span>Program</span>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>
    <!-- Breadcrumb Section End -->    

    <!-- Schedule Table Section Begin -->
    <section class="schedule-table-section spad">
        <div class="container">
            <div class="row">
                <div class="col-sm-12">
                    <div class="schedule-table-tab">
                        <ul class="nav nav-tabs" role="tablist">
                            <li class="nav-item">
                                <a class="nav-link active" data-toggle="tab" href="#tabs-1" role="tab">August 23</a>
                            </li>
                            <li class="nav-item">
                                <a class="nav-link" data-toggle="tab" href="#tabs-2" role="tab">August 24</a>
                            </li>
                            <li class="nav-item">
                                <a class="nav-link" data-toggle="tab" href="#tabs-3" role="tab">August 25</a>
                            </li>
                            <li class="nav-item">
                                <a class="nav-link" data-toggle="tab" href="#tabs-4" role="tab">August 26</a>
                            </li>
                            <li class="nav-item">
                                <a class="nav-link" data-toggle="tab" href="#tabs-5" role="tab">August 27</a>
                            </li>
                            <li class="nav-item">
                                <a class="nav-link" data-toggle="tab" href="#tabs-6" role="tab">August 28</a>
                            </li>
                        </ul>
                        <br>
                        <br>
                        <div class="tab-content">
                            <div class="tab-pane active" id="tabs-1" role="tabpanel">
                                    <div class="row">
                                        <div class="col-sm-12">
                                            <div class="speaker-item">
                                                <div class="row">
                                                    <div class="col-lg-4">
                                                        <div class="si-pic">
                                                            <h4><i class="fa fa-clock-o"></i>  04:00 - 06:00 PM </h4>
                                                        </div>
                                                    </div>
                                                    <div class="col-lg-8">
                                                        <div class="si-text">
                                                            <div class="si-title">
                                                                <h4>Pre-Boot Camp</h4>
                                                                <span>by Abhijeet Sharma</span>
                                                                <p>Overview of Machine Learning including, Supervised, Unsupervised, and Reinforcement Learning along with a broad discussion on some common ML techniques will be covered.</p>
                                                            </div>
                                                            <!-- <div class="si-social">
                                                                <a href="#"><i class="fa fa-facebook"></i></a>
                                                                <a href="#"><i class="fa fa-twitter"></i></a>
                                                                <a href="#"><i class="fa fa-google-plus"></i></a>
                                                            </div> -->
                                                           <!-- <button type="button" class="collapsible">Abstract</button>
                                                            <div class="content">
                                                                <p style="line-height: 1.2;">
                                                                   Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do 
                                                                eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim
                                                                 ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut 
                                                                 aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit 
                                                                 in voluptate velit esse cillum dolore eu fugiat nulla pariatur. 
                                                                 Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia 
                                                                 deserunt mollit anim id est laborum.</p>-->
                                                           </div>
                                                       </div>
                                                     </div>
                                                  </div>
                                                </div>
                                             </div>
                                          </div>
                            <div class="tab-pane" id="tabs-2" role="tabpanel">
                                <div class="row">
                                    <div class="col-sm-12">
                                        <div class="speaker-item">
                                            <div class="row">
                                                <div class="col-lg-4">
                                                    <div class="si-pic">
                                                        <h4><i class="fa fa-clock-o"></i> 04:00 - 05:30 PM</h4>
                                                    </div>
                                            </div>
                                            <div class="col-lg-8">
                                                <div class="si-text">
                                                    <div class="si-title">
                                                        <h4>Approaches towards explaining model predictions in NLP</h4>
                                                        <span>by Anirban Laha</span>
                                                        <!-- <h6 style="margin-top: 0.5em;"><i class="fa fa-youtube-play"></i> <a href="https://www.youtube.com/watch?v=7FynJtSqiZs" target="_blank">Watch on YouTube</a></h6>-->
                                                    </div>
                                                    <!-- <div class="si-social">
                                                        <a href="#"><i class="fa fa-facebook"></i></a>
                                                        <a href="#"><i class="fa fa-twitter"></i></a>
                                                        <a href="#"><i class="fa fa-google-plus"></i></a>
                                                    </div> -->
                                                    <button type="button" class="collapsible">Abstract</button>
                                                    <div class="content">
                                                        <p style="line-height: 1.2;">
                                                            With the advent of deep learning, a lot of progress has been made towards algorithm development to solve a plethora of practical problems in Natural Language Processing. These algorithms incorporate highly complex networks, which are becoming increasingly difficult to explain theoretically. The difficulty is exacerbated even further due to the recent trends of extremely large networks which are trained on datasets of size in the order of billions (for example, GPT-3). It has been seen that models often pick up a lot of human biases and spurious patterns from the data and can also lead to offensive results (like Microsoft Tay, or Amazon's Recruiting tool). Thus, it has become necessary to understand the working of these networks to establish trust and ensure fairness and safety before there are deployable in large production environments. Also, this understanding can help unravel shortcomings which can lead to better algorithm development. In recent years, various approaches have been proposed to explain model predictions in a network-agnostic way or with limited assumptions about the network. This talk will focus on these approaches in the context of NLP, starting with motivating applications, touching upon the basic paradigms of explainability, following up with discussion on influential approaches, and laying the ground for research gaps and current trends.</p>
                                                        </div>
                                                    </div>
                                                </div>
                                            </div>
                                        </div>
                                    </div>
                                </div>
                                <div class="row">
                                    <div class="col-sm-12">
                                        <div class="speaker-item">
                                            <div class="row">
                                                <div class="col-lg-4">
                                                    <div class="si-pic">
                                                        <h4><i class="fa fa-clock-o"></i> 06:00 - 07:30 PM </h4>
                                                    </div>
                                                </div>
                                                <div class="col-lg-8">
                                                    <div class="si-text">
                                                        <div class="si-title">
                                                            <h4>Explainability in Healthcare: From application oriented approaches to ethics of deployment</h4>
                                                            <span>by Shalmali Joshi</span>
                                                            <!--<h6 style="margin-top: 0.5em;"><i class="fa fa-youtube-play"></i> <a href="https://www.youtube.com/watch?v=UM4duofevFs" target="_blank">Watch on YouTube</a></h6>-->
                                                        </div>
                                                        <!-- <div class="si-social">
                                                            <a href="#"><i class="fa fa-facebook"></i></a>
                                                            <a href="#"><i class="fa fa-twitter"></i></a>
                                                            <a href="#"><i class="fa fa-google-plus"></i></a>
                                                        </div> -->
                                                        <button type="button" class="collapsible">Abstract</button>
                                                        <div class="content">
                                                             <p style="line-height: 1.2;">
                                                                Machine learning-based tools are increasingly being considered a valuable tool for providing clinical care. XAI is often used to increase trust and the adoption of such tools in healthcare applications. In this talk, I will discuss an approach to Explainability in Machine Learning grounded in the applications. I will demonstrate that understanding users' needs can guide the technical development of novel explanation methods. I will provide an overview of explainability techniques developed in the context of healthcare. Next, I will demonstrate why explanations can be misleading and miscalibrate user trust, especially in high-stakes applications like healthcare, and should be validated with care. Finally, I will talk about how developing good XAI techniques for any application domain should be guided by the ethics of the application domain and how that, in turn, sets a high and domain-specific standard of validation of explainability methods themselves.</p>
                                                        </div>
                                                    </div>
                                                </div>
                                            </div>
                                        </div>
                                    </div>
                                </div>
                            </div>   
                            <div class="tab-pane" id="tabs-3" role="tabpanel">
                                <div class="row">
                                    <div class="col-sm-12">
                                        <div class="speaker-item">
                                            <div class="row">
                                                <div class="col-lg-4">
                                                    <div class="si-pic">
                                                        <h4><i class="fa fa-clock-o"></i> 04:00 - 05:30 PM</h4>
                                                    </div>
                                                </div>
                                                <div class="col-lg-8">
                                                    <div class="si-text">
                                                        <div class="si-title">
                                                            <h4> Explainable AI: An Introduction and Overview</h4>
                                                            <span>by Vineeth N Balasubramanian</span>
                                                        <!-- <h6 style="margin-top: 0.5em;"><i class="fa fa-youtube-play"></i> <a href="https://www.youtube.com/watch?v=7FynJtSqiZs" target="_blank">Watch on YouTube</a></h6>-->
                                                        </div>
                                                        <!-- <div class="si-social">
                                                            <a href="#"><i class="fa fa-facebook"></i></a>
                                                            <a href="#"><i class="fa fa-twitter"></i></a>
                                                            <a href="#"><i class="fa fa-google-plus"></i></a>
                                                        </div> -->
                                                        <button type="button" class="collapsible">Abstract</button>
                                                        <div class="content">
                                                            <p style="line-height: 1.2;">
                                                                The last decade has seen rapid strides in Artificial Intelligence (AI) moving from being a fantasy to a reality that is a part of each one of our lives, embedded in various technologies. A catalyst of this rapid uptake has been the enormous success of deep learning methods for addressing problems in various domains including computer vision, natural language processing, and speech understanding. However, as AI makes its way into risk-sensitive and safety-critical applications such as healthcare, aerospace and finance, it is essential for AI models to not only make predictions but also be able to explain their predictions. This talk will introduce the audience to this increasingly important area of explainable AI (XAI), as well as present an overview of existing methods in XAI -- focusing on methods used in tandem with deep neural network models.</p>
                                                        </div>
                                                    </div>
                                                </div>
                                            </div>
                                        </div>
                                    </div>
                                </div>
                                <div class="row">
                                    <div class="col-sm-12">
                                        <div class="speaker-item">
                                            <div class="row">
                                                <div class="col-lg-4">
                                                    <div class="si-pic">
                                                        <h4><i class="fa fa-clock-o"></i> 06:00 - 07:30 PM </h4>
                                                    </div>
                                                </div>
                                                <div class="col-lg-8">
                                                    <div class="si-text">
                                                        <div class="si-title">
                                                            <h4>Explainabiltiy in Sequential Decision-Making Problems</h4>
                                                            <span>by Tathagata Chakraborti</span>
                                                            <!--<h6 style="margin-top: 0.5em;"><i class="fa fa-youtube-play"></i> <a href="https://www.youtube.com/watch?v=UM4duofevFs" target="_blank">Watch on YouTube</a></h6>-->
                                                        </div>
                                                        <!-- <div class="si-social">
                                                            <a href="#"><i class="fa fa-facebook"></i></a>
                                                            <a href="#"><i class="fa fa-twitter"></i></a>
                                                            <a href="#"><i class="fa fa-google-plus"></i></a>
                                                        </div> -->
                                                        <button type="button" class="collapsible">Abstract</button>
                                                        <div class="content">
                                                         <p style="line-height: 1.2;">
                                                                The world of Explainable AI is rapidly expanding in scope from classification tasks to more complex decision-making processes where AI algorithms play an outsized role. Arguably, such settings bring out more challenging problems in XAI since they involve interactions with the end-user rather than explanations for purposes of debugging. In this talk, I will give a whirlwind tour of the many domains where such explainability issues manifest and the role of mental modeling as an underlying theme in designing the explainability of AI algorithms in all those domains.</p>
                                                        </div>
                                                    </div>
                                                </div>
                                            </div>
                                        </div>
                                    </div>
                                </div> 
                            </div>
                            <div class="tab-pane" id="tabs-4" role="tabpanel">
                                <div class="row">
                                    <div class="col-sm-12">
                                        <div class="speaker-item">
                                            <div class="row">
                                                <div class="col-lg-4">
                                                    <div class="si-pic">
                                                        <h4><i class="fa fa-clock-o"></i> 06:00 - 09:00 PM</h4>
                                                    </div>
                                                </div>
                                                <div class="col-lg-8">
                                                    <div class="si-text">
                                                        <div class="si-title">
                                                            <h4>Explainable AI: From Correlation to Causation</h4>
                                                            <span>by Karthikeyan Shanmugam</span>
                                                            <!--<h6 style="margin-top: 0.5em;"><i class="fa fa-youtube-play"></i> <a href="https://www.youtube.com/watch?v=7FynJtSqiZs" target="_blank">Watch on YouTube</a></h6>-->
                                                        </div>
                                                        <!-- <div class="si-social">
                                                            <a href="#"><i class="fa fa-facebook"></i></a>
                                                            <a href="#"><i class="fa fa-twitter"></i></a>
                                                            <a href="#"><i class="fa fa-google-plus"></i></a>
                                                        </div> -->
                                                        <button type="button" class="collapsible">Abstract</button>
                                                        <div class="content">
                                                            <p style="line-height: 1.2;">
                                                                "As artificial intelligence and machine learning algorithms make further inroads into society, calls are increasing from multiple stakeholders for these algorithms 
                                                                to explain their outputs. At the same time, these stakeholders, whether they be affected citizens, government regulators, domain experts, or system developers,
                                                                present different requirements for explanations. We in this tutorial, first provide a broad overview of the field in terms of types of methods each of which may be
                                                                appropriate in different scenarios. Overview would cover different types of interpretable methods including directly interpretable models, prototype generation and 
                                                                local explanations In the second part of the tutorial, we will introduce the notion of contrastive explanations. We will first explore bi-factual contrastive explanations 
                                                                and discuss some methods that provide such explanations. Then, we explore contrastive explanations that are counterfactual in nature. We will define the notion of
                                                                counterfactuals from the “actual causality” perspective and specify what assumptions are needed to estimate it in general from within a Pearlian framework. We will discuss
                                                                recent works that provide a principled way to reason about counterfactuals that use a combination of causal assumptions and data driven methods. We will discuss open
                                                                problems relating to counterfactual explanations."</p>
                                                        </div>
                                                    </div>
                                                </div>
                                            </div>
                                        </div>
                                    </div>
                                </div>
                                <div class="row">
                                    <div class="col-sm-12">
                                        <div class="speaker-item">
                                            <div class="row">
                                                <div class="col-lg-4">
                                                    <div class="si-pic">
                                                        <h4><i class="fa fa-clock-o"></i> 06:00 - 09:00 PM </h4>
                                                    </div>
                                                </div>
                                                <div class="col-lg-8">
                                                    <div class="si-text">
                                                        <div class="si-title">
                                                            <h4>Amit Dhurandhar</h4>
                                                            <!--<span>by Narayanan Unny</span>
                                                            <h6 style="margin-top: 0.5em;"><i class="fa fa-youtube-play"></i> <a href="https://www.youtube.com/watch?v=UM4duofevFs" target="_blank">Watch on YouTube</a></h6>
                                                        </div>
                                                        <!-- <div class="si-social">
                                                            <a href="#"><i class="fa fa-facebook"></i></a>
                                                            <a href="#"><i class="fa fa-twitter"></i></a>
                                                            <a href="#"><i class="fa fa-google-plus"></i></a>
                                                        </div> -->
                                                        <!--<button type="button" class="collapsible">Abstract</button>
                                                        <div class="content">
                                                        <!-- <p style="line-height: 1.2;">
                                                                Explanations of complex models need to be adapted based on requirements of its 
                                                                application and usage. The explanation can be in the forms of rules or plain 
                                                                feature attributions. It could cover the whole model as global explanations 
                                                                or specific data points as local explanations. This talk would motivate the 
                                                                need to choose the form and granularity of explanations based on the application 
                                                                it is intended for and provide a new explanation method – LMTE that offers the
                                                                flexibility of forms and granularities of explanations.</p>-->
                                                        </div>
                                                    </div>
                                                </div>
                                            </div>
                                        </div>
                                    </div>
                                </div> 
                            </div>
                            <div class="tab-pane" id="tabs-5" role="tabpanel">
                                <div class="row">
                                    <div class="col-sm-12">
                                        <div class="speaker-item">
                                            <div class="row">
                                                <div class="col-lg-4">
                                                    <div class="si-pic">
                                                        <h4><i class="fa fa-clock-o"></i> 04:00 - 05:30 PM</h4>
                                                    </div>
                                                </div>
                                                <div class="col-lg-8">
                                                    <div class="si-text">
                                                        <div class="si-title">
                                                            <h4>Towards Interpretable AI: Visualization of learned neural models</h4>
                                                            <span>by Harish Guruprasad</span>
                                                            <!--<h6 style="margin-top: 0.5em;"><i class="fa fa-youtube-play"></i> <a href="https://www.youtube.com/watch?v=7FynJtSqiZs" target="_blank">Watch on YouTube</a></h6>-->
                                                        </div>
                                                        <!-- <div class="si-social">
                                                            <a href="#"><i class="fa fa-facebook"></i></a>
                                                            <a href="#"><i class="fa fa-twitter"></i></a>
                                                            <a href="#"><i class="fa fa-google-plus"></i></a>
                                                        </div> -->
                                                        <button type="button" class="collapsible">Abstract</button>
                                                        <div class="content">
                                                            <p style="line-height: 1.2;">
                                                               Models trained from data using machine learning are becoming ubiquitous: from tagging your friends on a Facebook photo to auto-approving an insurance claim and even more. While they do remarkably well on average, 
                                                                sometimes they have quirks that cannot be understood and can potentially hurt an individual. In particular, with the ascendance of neural networks and deep learning, 
                                                                each model often does millions of multiplications and additions to make a single prediction and hence it is not possible to interpret the reasoning behind such decisions. 
                                                                This has led to explosive growth in a rich new field known variously as interpretable or explainable AI. The broad goal of interpretable or explainable AI is to aid humans
                                                                in understanding AI models and individual model decisions. In this talk, we will see a broad overview of various analytical and visualization techniques that enable this field.</p>
                                                        </div>
                                                    </div>
                                                </div>
                                            </div>
                                        </div>
                                    </div>
                                </div>
                                    <div class="row">
                                        <div class="col-sm-12">
                                            <div class="speaker-item">
                                                <div class="row">
                                                    <div class="col-lg-4">
                                                        <div class="si-pic">
                                                            <h4><i class="fa fa-clock-o"></i> 06:00 - 07:30 PM</h4>
                                                        </div>
                                                    </div>
                                                    <div class="col-lg-8">
                                                        <div class="si-text">
                                                            <div class="si-title">
                                                                <h4> One Explanation Does Not Fit All: A hands-on session on AI Explainability 360 Toolkit</h4>
                                                                <span>by Vijay Arya</span>
                                                                <!--<h6 style="margin-top: 0.5em;"><i class="fa fa-youtube-play"></i> <a href="https://www.youtube.com/watch?v=UM4duofevFs" target="_blank">Watch on YouTube</a></h6>-->
                                                            </div>
                                                            <!-- <div class="si-social">
                                                                <a href="#"><i class="fa fa-facebook"></i></a>
                                                                <a href="#"><i class="fa fa-twitter"></i></a>
                                                                <a href="#"><i class="fa fa-google-plus"></i></a>
                                                            </div> -->
                                                            <button type="button" class="collapsible">Abstract</button>
                                                            <div class="content">
                                                               <p style="line-height: 1.2;">
                                                                    As machine learning algorithms make further inroads into society, calls are increasing from multiple 
                                                                   stakeholders for these algorithms to explain their outputs. Moreover, these stakeholders, whether they 
                                                                   be government regulators, affected citizens, domain experts, or developers, present different requirements 
                                                                   for explanations. To address these needs, we introduce AI Explainability 360, an open-source software
                                                                   toolkit featuring eight diverse state-of-the-art explainability methods, two evaluation metrics, and 
                                                                   an extensible software architecture that organizes these methods according to their use in the AI 
                                                                   modeling pipeline. Additionally, we have implemented several enhancements to bring research innovations 
                                                                   closer to consumers of explanations, ranging from simplified, more accessible versions of algorithms, 
                                                                   to guidance material to help users navigate the space of explanations along with tutorials and an 
                                                                   interactive web demo to introduce AI explainability to practitioners. Together, our toolkit can help 
                                                                   improve transparency of machine learning models and provides a platform to integrate new explainability
                                                                   techniques as they are developed.l be a hands-on session in which users will experiment with code from <a href="https://github.com/Trusted-AI/AIX360" target="_blank">Visit></a></p>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            </div>
                                        </div>
                                    </div>
                                </div>
                                <div class="tab-pane" id="tabs-6" role="tabpanel">
                                    <center><h4 style="font-weight: 600;">Research Showcase</h4></center>
                                    <!-- <div class="row">
                                        <div class="col-sm-12">
                                            <div class="speaker-item">
                                                <div class="row">
                                                    <div class="col-lg-4">
                                                        <div class="si-pic">
                                                            <h4><i class="fa fa-clock-o"></i> 04:00 - 05:30 PM</h4>
                                                        </div>
                                                    </div>
                                                    <div class="col-lg-8">
                                                        <div class="si-text">
                                                            <div class="si-title">
                                                                <h4>Harish Guruprasad</h4> -->
                                                                <!--<span>by Bootcamp</span>-->
                                                            <!-- <h6 style="margin-top: 0.5em;"><i class="fa fa-youtube-play"></i> <a href="https://www.youtube.com/watch?v=7FynJtSqiZs" target="_blank">Watch on YouTube</a></h6>
                                                            </div>
                                                            <!-- <div class="si-social">
                                                                <a href="#"><i class="fa fa-facebook"></i></a>
                                                                <a href="#"><i class="fa fa-twitter"></i></a>
                                                                <a href="#"><i class="fa fa-google-plus"></i></a>
                                                            </div> -->
                                                            <!--<button type="button" class="collapsible">Abstract</button>
                                                            <div class="content">
                                                                <p style="line-height: 1.2;">
                                                                    As deep neural network models get absorbed into real-world applications each day, there is an 
                                                                    impending need to explain the decisions of these neural network models. In particular, while
                                                                    existing methods for neural network attributions (for explanations) are largely statistical,
                                                                    we propose a new attribution method for neural networks developed using first principles of 
                                                                    causality (to the best of our knowledge, the first such). The neural network architecture is
                                                                    viewed as a Structural Causal Model, and a methodology to compute the causal effect of each
                                                                    feature on the output is presented. With reasonable assumptions on the causal structure of the 
                                                                    input data, we propose algorithms to efficiently compute the causal effects, as well as scale
                                                                    the approach to data with large dimensionality. We also show how this method can be used for 
                                                                    recurrent neural networks. We report experimental results on both simulated and real datasets 
                                                                    showcasing the promise and usefulness of the proposed algorithm. This work was presented as a 
                                                                    Long Oral at ICML 2019 (http://proceedings.mlr.press/v97/chattopadhyay19a.html). This talk will
                                                                    also include an overview of our other recent efforts in exploring causal inference towards explainable AI.</p>-->
                                                            <!-- </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            </div>
                                        </div>
                                    </div> -->
                                    <!-- <div class="row">
                                        <div class="col-sm-12">
                                            <div class="speaker-item">
                                                <div class="row">
                                                    <div class="col-lg-4">
                                                        <div class="si-pic">
                                                            <h4><i class="fa fa-clock-o"></i> 06:00 - 07:30 PM </h4>
                                                        </div>
                                                    </div>
                                                    <div class="col-lg-8">
                                                        <div class="si-text">
                                                        <div class="si-title">
                                                                <h4>Shalmali Joshi</h4> -->
                                                                <!--<span>by Narayanan Unny</span>
                                                                <h6 style="margin-top: 0.5em;"><i class="fa fa-youtube-play"></i> <a href="https://www.youtube.com/watch?v=UM4duofevFs" target="_blank">Watch on YouTube</a></h6>
                                                            </div>
                                                            <!-- <div class="si-social">
                                                                <a href="#"><i class="fa fa-facebook"></i></a>
                                                                <a href="#"><i class="fa fa-twitter"></i></a>
                                                                <a href="#"><i class="fa fa-google-plus"></i></a>
                                                            </div> -->
                                                            <!--<button type="button" class="collapsible">Abstract</button>
                                                            <div class="content">
                                                            <!-- <p style="line-height: 1.2;">
                                                                    Explanations of complex models need to be adapted based on requirements of its 
                                                                    application and usage. The explanation can be in the forms of rules or plain 
                                                                    feature attributions. It could cover the whole model as global explanations 
                                                                    or specific data points as local explanations. This talk would motivate the 
                                                                    need to choose the form and granularity of explanations based on the application 
                                                                    it is intended for and provide a new explanation method – LMTE that offers the
                                                                    flexibility of forms and granularities of explanations.</p>-->
                                                        <!-- </div>
                                                    </div>
                                                </div>
                                            </div>
                                        </div> -->
                                    </div>
                                </div>
                            </div>
                       </div>
                    </div>
                </div>
            </div>
        </div>
    </section>
    <!-- Schedule Table Section End -->

    <!-- Newslatter Section Begin -->
    <!-- <section class="newslatter-section about-newslatter">
        <div class="container" style="padding-bottom: 3em;">
            <div class="newslatter-inner set-bg">
                <h2 style="text-align: center; color: #000;">To be released soon</h2>
            </div>
        </div>
    </section> -->
    <!-- Newslatter Section End -->

    <!-- Contact Section Begin -->
    <!-- <section class="contact-section spad">
        <div class="container">
            <div class="row">
                <div class="col-lg-6">
                    <div class="section-title">
                        <h2>Location</h2>
                        <p>Get directions to our event center</p>
                    </div>
                    <div class="cs-text">
                        <div class="ct-address">
                            <span>Address:</span>
                            <p>01 Pascale Springs Apt. 339, NY City <br />United State</p>
                        </div>
                        <ul>
                            <li>
                                <span>Phone:</span>
                                (+12)-345-67-8910
                            </li>
                            <li>
                                <span>Email:</span>
                                info.colorlib@gmail.com
                            </li>
                        </ul>
                        <div class="ct-links">
                            <span>Website:</span>
                            <p>https://conference.colorlib.com</p>
                        </div>
                    </div>
                </div>
                <div class="col-lg-6">
                    <div class="cs-map">
                        <iframe
                            src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d52901.38789495531!2d-118.19465514866786!3d34.03523211493029!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x80c2cf71ad83ff9f%3A0x518b28657f4543b7!2sEast%20Los%20Angeles%2C%20CA%2C%20USA!5e0!3m2!1sen!2sbd!4v1579763856144!5m2!1sen!2sbd"
                            height="400" style="border:0;" allowfullscreen=""></iframe>
                    </div>
                </div>
            </div>
        </div>
    </section> -->
    <!-- Contact Section End -->

    <!-- Footer Section Begin -->
    <footer class="footer-section">
        <div class="container">
            <div class="row">
                <div class="col-lg-12">
                    <div class="footer-text">
                        <div class="ft-logo">
                            <a href="https://rbcdsai.iitm.ac.in/">
                            <img src="img/logo_main.png" height=75 alt="">
                            </a>
                        </div>
                        <ul>
                            <li><a href="./index.html">Home</a></li>
                            <!-- <li><a href="./call-for-papers.html">Call for Papers</a></li> -->
                            <li><a href="./program.html">Program</a></li>
                            <li><a href="./speaker.html">Speakers</a></li>                            
                            <li><a href="organizers.html">Organizers</a></li>
                            <li>|</li>
                            <li><a href="mailto:contact@rbcdsai.org">Mail us</a></li>
                        </ul>
                        <div class="copyright-text"><p><!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. -->
  Copyright &copy;<script>document.write(new Date().getFullYear());</script> All rights reserved | This template is made with <i class="fa fa-heart" aria-hidden="true"></i> by <a href="https://colorlib.com" target="_blank">Colorlib</a>
  <!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. --></p></div>
                        <div class="ft-social">
                            <a href="https://www.facebook.com/rbcdsai" target="_blank"><i class="fa fa-facebook"></i></a>
                            <a href="https://twitter.com/rbc_dsai_iitm" target="_blank"><i class="fa fa-twitter"></i></a>
                            <a href="https://www.linkedin.com/company/rbcdsai/" target="_blank"><i class="fa fa-linkedin"></i></a>
                            <a href="https://www.instagram.com/rbcdsai/" target="_blank"><i class="fa fa-instagram"></i></a>
                            <a href="https://www.youtube.com/channel/UCKaYqGvmULmTrN0PH5YPFcA" target="_blank"><i class="fa fa-youtube-play"></i></a>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </footer>
    <!-- Footer Section End -->

    <!-- Js Plugins -->
    <script src="js/jquery-3.3.1.min.js"></script>
    <script src="js/bootstrap.min.js"></script>
    <script src="js/jquery.magnific-popup.min.js"></script>
    <script src="js/jquery.countdown.min.js"></script>
    <script src="js/jquery.slicknav.js"></script>
    <script src="js/owl.carousel.min.js"></script>
    <script src="js/main.js"></script>
</body>

</html>
